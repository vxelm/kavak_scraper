{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/csv/cleaned_final_csv.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "#### df info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "#### ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Brand', 'Tipo', 'Sucursal', 'Year', 'Km', 'Caja', 'Precio']\n",
    "df_ml = df[cols].copy()\n",
    "\n",
    "# Convertir ['Caja', 'Sucursal'] a columnas numericas\n",
    "df_ml = pd.get_dummies(df_ml, columns=['Caja', 'Sucursal', 'Tipo'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_ml.drop(columns=['Precio'])\n",
    "y = df_ml['Precio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dividir datos en train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Entranamiento: {X_train.shape[0]} autos\")\n",
    "print(f\"Examen (Test): {X_test.shape[0]} autos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Target Encoding\n",
    "\n",
    "# Unir los precios temporalmente para calcular los promedios\n",
    "train_temp = X_train.copy()\n",
    "train_temp['Precio_Real'] = y_train\n",
    "# Calcular precios promedio para cada Marca y Modelo\n",
    "brand_map = train_temp.groupby('Brand')['Precio_Real'].mean() # {'marca': #####}\n",
    "#model_map = train_temp.groupby('Model')['Precio_Real'].mean() # {'modelo': #####}\n",
    "global_mean = y_train.mean() \n",
    "# Remplazo de marcas y modelos por precio promedio en train\n",
    "X_train['Brand_Encoded'] = X_train['Brand'].map(brand_map) #VLOOKUP para precio promedio de cada marca\n",
    "#X_train['Model_Encoded'] = X_train['Model'].map(model_map) #VLOOKUP para precio promedio de cada modelo\n",
    "\n",
    "# Remplazo de marcas y modelos por precio promedio en test\n",
    "X_test['Brand_Encoded'] = X_test['Brand'].map(brand_map)\n",
    "#X_test['Model_Encoded'] = X_test['Model'].map(model_map)\n",
    "\n",
    "# Limpieza de nulos por media de cada marca por si hay un modelo que no estaba en train\n",
    "X_test['Brand_Encoded'] = X_test['Brand_Encoded'].fillna(global_mean)\n",
    "# X_test['Model_Encoded'] = X_test['Model_Encoded'].fillna(global_mean)\n",
    "\n",
    "# Eliminar columnas originales\n",
    "X_train = X_train.drop(columns=['Brand'])\n",
    "X_test = X_test.drop(columns=['Brand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Entrenamiento\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prediccion\n",
    "y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluacion\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo del Error Porcentual Promedio (MAPE)\n",
    "errores = abs(y_test - y_pred)\n",
    "mape = 100 * np.mean(errores / y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- RESULTADOS DEL MODELO ---\")\n",
    "print(f\"MAE (Error Promedio en Pesos):  ${mae:,.2f} MXN\")\n",
    "print(f\"MAPE (Error Promedio %):        {mape:.2f}%\")\n",
    "print(f\"R2 (Precisión General):         {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- EJEMPLO REAL ---\")\n",
    "# Comparemos el primer auto del Test Set\n",
    "precio_real = y_test.iloc[0]\n",
    "precio_predicho = y_pred[0]\n",
    "diferencia = precio_predicho - precio_real\n",
    "\n",
    "print(f\"Auto de prueba #1:\")\n",
    "print(f\"Precio Real Kavak:   ${precio_real:,.2f}\")\n",
    "print(f\"El Modelo predice:   ${precio_predicho:,.2f}\")\n",
    "print(f\"Diferencia:          ${diferencia:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extraemos la importancia de cada variable\n",
    "importances = rf_model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Creamos una tabla\n",
    "df_imp = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "df_imp = df_imp.sort_values('Importance', ascending=False)\n",
    "\n",
    "# Mostramos el TOP 5\n",
    "print(df_imp.head(5))\n",
    "\n",
    "# Graficamos\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(df_imp['Feature'].head(10), df_imp['Importance'].head(10), color='salmon')\n",
    "plt.xlabel('Importancia (0 a 1)')\n",
    "plt.title('¿Quién le sopló la respuesta al modelo?')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kavak_scrapper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
