{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68c4cdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.dialects.postgresql import insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d0372df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURACI√ìN\n",
    "# user:password@host:port/dbname\n",
    "# Nota: Si corres esto desde WSL/Windows (fuera de la red Docker), el host es 'localhost'.\n",
    "# Si lo corres DESDE otro contenedor, el host es 'warehouse'.\n",
    "DB_URL = \"postgresql://admin_data:root_password_seguro@localhost:5432/kavak_db\"\n",
    "INPUT_FILE = \"../data/raw/kavak_raw_data.jsonl\" # Ajusta la ruta seg√∫n desde donde ejecutes\n",
    "\n",
    "def get_db_connection():\n",
    "    return create_engine(DB_URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b77c27a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_load():\n",
    "    print(\"üöÄ Iniciando carga a PostgreSQL...\")\n",
    "    \n",
    "    # 1. LEER JSONL (Igual que antes)\n",
    "    data = []\n",
    "    if not os.path.exists(INPUT_FILE):\n",
    "        print(f\"‚ùå No encuentro {INPUT_FILE}\")\n",
    "        return\n",
    "\n",
    "    with open(INPUT_FILE, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                data.append(json.loads(line))\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    # 2. TRANSFORMAR A DATAFRAME (Igual que antes)\n",
    "    processed_data = []\n",
    "    for entry in data:\n",
    "        try:\n",
    "            raw = entry['raw_data']\n",
    "            car = next((item for item in raw.get('@graph', []) if item.get('@type') == 'Car'), None)\n",
    "            \n",
    "            if car:\n",
    "                # Extraemos el ID del final de la URL si no viene expl√≠cito\n",
    "                # Ejemplo URL: .../kia-forte-2017 -> id: kia-forte-2017\n",
    "                internal_id = entry['source_url'].split('/')[-1]\n",
    "                \n",
    "                processed_data.append({\n",
    "                    'id_interno': internal_id,\n",
    "                    'url': entry['source_url'],\n",
    "                    'marca': car.get('brand', {}).get('name', 'Desconocido'),\n",
    "                    'modelo': car.get('model', 'Desconocido'),\n",
    "                    'version': car.get('vehicleConfiguration', 'N/A'),\n",
    "                    'anio': int(car.get('vehicleModelDate', 0) or 0),\n",
    "                    'precio_mxn': int(car.get('offers', {}).get('price', 0) or 0),\n",
    "                    'km': int(car.get('mileageFromOdometer', {}).get('value', 0) or 0),\n",
    "                    'transmision': car.get('vehicleTransmission', 'N/A'),\n",
    "                    'ciudad': 'Mexico',\n",
    "                    'fecha_extraccion': pd.to_datetime(entry['extracted_at'], unit='s').date()\n",
    "                })\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    df = pd.DataFrame(processed_data)\n",
    "    # Deduplicaci√≥n en Pandas antes de intentar subir (Optimizaci√≥n)\n",
    "    # Nos quedamos con el √öLTIMO registro encontrado para cada ID (el m√°s reciente)\n",
    "    df = df.drop_duplicates(subset=['id_interno'], keep='last')\n",
    "    \n",
    "    print(f\"   üìâ Registros √∫nicos a insertar: {len(df)}\")\n",
    "\n",
    "    # 3. CARGAR (Upsert - Insert or Update)\n",
    "    # Pandas to_sql es limitado para Upserts, as√≠ que usamos un truco simple:\n",
    "    # 'append' fallar√° si hay duplicados. \n",
    "    # Para hacerlo profesional, usamos to_sql pero manejando errores o usando sqlalchemy core.\n",
    "    # POR AHORA: Usaremos 'append' pero como ya limpiamos duplicados en el paso anterior (drop_duplicates),\n",
    "    # y la tabla est√° vac√≠a o limpia, funcionar√°.\n",
    "    \n",
    "    engine = get_db_connection()\n",
    "    \n",
    "    try:\n",
    "        # method='multi' acelera la carga\n",
    "        df.to_sql('autos_silver', engine, if_exists='append', index=False, method='multi', chunksize=1000)\n",
    "        print(\"   ‚úÖ Carga completada en Postgres.\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Error en carga (probablemente IDs repetidos en DB): {e}\")\n",
    "        print(\"   üí° Tip: En producci√≥n usar√≠amos INSERT ON CONFLICT DO UPDATE.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e3874b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    process_and_load()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kavak_scrapper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
